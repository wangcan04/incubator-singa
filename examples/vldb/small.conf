name: "mlp"
train_steps: 120
test_steps:10
test_freq:60
disp_freq:10
train_one_batch {
  alg: kBP
}
updater{
  type: kSGD
  learning_rate{
    type : kStep
    base_lr: 0.001
    step_conf{
      change_freq: 60
      gamma: 0.997
    }
  }
}
neuralnet {
  layer {
    name: "data"
    type: kShardData
    sharddata_conf {
      path: "examples/mnist/mnist_train_shard"
      batchsize: 1000
    }
    exclude: kTest
  }

  layer {
    name: "data"
    type: kShardData
    sharddata_conf {
      path: "examples/mnist/mnist_test_shard"
      batchsize: 1000
    }
    exclude: kTrain
  }

  layer{
    name:"mnist"
    type: kMnist
    srclayers: "data"
    mnist_conf {
      norm_a: 127.5
      norm_b: 1
    }
  }
  layer{
    name: "hid1"
    user_type: "kHidden"
    srclayers:"mnist"
    [hidden_conf] {
      num_output: 2500
    }
    param{
      name: "w1"
      init {
        type: kUniform
        low:-0.05
        high:0.05
      }
    }
    param{
      name: "b1"
      init {
        type : kUniform
        low: -0.05
        high:0.05
      }
    }
  }
 layer{
    name: "loss"
    user_type:kSoftmaxLoss
    softmaxloss_conf{
      topk:1
    }
    srclayers:"hid1"
    srclayers:"label"
  }
}
cluster {
  nworker_groups: 1
  nserver_groups: 1
  workspace: "examples/mnist"
}
